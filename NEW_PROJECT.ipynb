{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXzLmt+mN6azE5f9meKztp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshnisv/Google_Play_Store/blob/main/NEW_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5M80STIPq1O",
        "outputId": "521c14e1-c472-401e-e9dc-0099c6cd60fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "NLP = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "UNIQUE_WORDS = {\n",
        "    \"topic_modeling\": [\"lda\", \"tf\", \"topic distribution\", \"text\", \"classification\", \"topic\"],\n",
        "    \"big_data\": [\"volume\", \"value\", \"data lake\", \"hadoop\", \"velocity\", \"veracity\"],\n",
        "    \"problem_solving\": [\"approach\", \"solution\", \"methodology\", \"steps\", \"break down\"],\n",
        "}\n",
        "\n",
        "CRITERIA_WEIGHTS = {\n",
        "    \"technical_knowledge\": 0.6,\n",
        "    \"problem_solving\": 0.2,\n",
        "    \"communication\": 0.2\n",
        "}\n",
        "\n",
        "candidate_responses = {\n",
        "    \"candidate_1\": {\n",
        "        \"topic_modeling\": \"I am familiar with LDA for topic modeling, which helps identify hidden topics in a corpus. It analyzes term frequency and generates a topic distribution for each document, allowing for effective text classification.\",\n",
        "        \"big_data\": \"In big data, volume refers to the enormous amounts of data generated. We use data lakes for storage, and Hadoop for processing. Velocity highlights the need for real-time data analysis, while value emphasizes extracting actionable insights.\",\n",
        "        \"problem_solving\": \"My approach to problem-solving involves breaking down complex issues into manageable steps, exploring various methodologies, and finding solutions that best fit the context.\"\n",
        "    },\n",
        "    \"candidate_2\": {\n",
        "        \"topic_modeling\": \"I have worked with TF in topic modeling to assess the importance of words. By analyzing the distribution of topics across texts, we can classify documents effectively and uncover underlying themes.\",\n",
        "        \"big_data\": \"Volume is critical in big data, as it dictates how we store and process information. I often use Hadoop to handle large datasets and leverage data lakes for their flexibility. Understanding velocity is key for real-time applications, and ensuring data veracity is essential for quality analysis.\",\n",
        "        \"problem_solving\": \"When tackling problems, I follow a structured methodology. First, I identify the problem, then I brainstorm potential solutions, and finally, I implement and test my approach in steps to ensure effectiveness.\"\n",
        "    },\n",
        "    \"candidate_3\": {\n",
        "        \"topic_modeling\": \"In my experience, LDA is a robust method for topic modeling. It helps in understanding the classification of documents based on topics. Term frequency plays a significant role in generating accurate topic distributions.\",\n",
        "        \"big_data\": \"Big data encompasses various dimensions, including velocity and volume. I utilize data lakes for storing large volumes of unstructured data and use Hadoop for distributed processing. The value derived from big data insights can drive strategic decisions.\",\n",
        "        \"problem_solving\": \"My problem-solving strategy involves a systematic approach: first, I define the problem, followed by a deep analysis of possible solutions, and then I break down the process into actionable steps for implementation.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def evaluate_response(response: str, keywords: list) -> float:\n",
        "    doc = NLP(response)\n",
        "    matched_keywords = [token.text.lower() for token in doc if token.text.lower() in keywords]\n",
        "    return len(matched_keywords) / len(keywords)\n",
        "\n",
        "def evaluate_candidate(candidate: dict) -> dict:\n",
        "    scores = {\n",
        "        \"technical_knowledge\": 0.0,\n",
        "        \"problem_solving\": 0.0,\n",
        "        \"communication\": 0.0\n",
        "    }\n",
        "\n",
        "    scores[\"technical_knowledge\"] += evaluate_response(candidate[\"topic_modeling\"], UNIQUE_WORDS[\"topic_modeling\"])\n",
        "    scores[\"technical_knowledge\"] += evaluate_response(candidate[\"big_data\"], UNIQUE_WORDS[\"big_data\"])\n",
        "\n",
        "    scores[\"problem_solving\"] += evaluate_response(candidate[\"problem_solving\"], UNIQUE_WORDS[\"problem_solving\"])\n",
        "\n",
        "    scores[\"technical_knowledge\"] /= 2\n",
        "\n",
        "    return scores\n",
        "\n",
        "def overall_score(scores: dict) -> float:\n",
        "    total_score = 0.0\n",
        "    for criterion, score in scores.items():\n",
        "        total_score += score * CRITERIA_WEIGHTS[criterion]\n",
        "    return total_score\n",
        "\n",
        "for candidate_name, responses in candidate_responses.items():\n",
        "    candidate_scores = evaluate_candidate(responses)\n",
        "    final_score = overall_score(candidate_scores)\n",
        "    print(f\"Candidate: {candidate_name}, Scores: {candidate_scores}, Final Score: {final_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS2jPyeaQLWq",
        "outputId": "91f37e5f-e98b-4880-ad65-a5a1d503d108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate: candidate_1, Scores: {'technical_knowledge': 0.75, 'problem_solving': 0.4, 'communication': 0.0}, Final Score: 0.53\n",
            "Candidate: candidate_2, Scores: {'technical_knowledge': 0.5, 'problem_solving': 0.6, 'communication': 0.0}, Final Score: 0.42\n",
            "Candidate: candidate_3, Scores: {'technical_knowledge': 0.6666666666666666, 'problem_solving': 0.4, 'communication': 0.0}, Final Score: 0.48\n"
          ]
        }
      ]
    }
  ]
}